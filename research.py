import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import re
import matplotlib as mpl
from wordcloud import WordCloud
from io import BytesIO
from docx import Document # ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á python-docx

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ---
font_path = "Kanit-Regular.ttf" 

def setup_font():
    try:
        mpl.font_manager.fontManager.addfont(font_path)
        prop = mpl.font_manager.FontProperties(fname=font_path)
        mpl.rc('font', family=prop.get_name())
        mpl.rcParams['axes.unicode_minus'] = False 
        return True
    except:
        return False

# --- 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÅ‡∏ö‡∏ö‡∏ú‡∏™‡∏°‡∏ú‡∏™‡∏≤‡∏ô ---
def analyze_sentiment_thai(text):
    pos_words = ['‡∏î‡∏µ', '‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢', '‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏à', '‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç', '‡∏û‡∏±‡∏í‡∏ô‡∏≤', '‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå', '‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô', '‡∏û‡∏≠‡πÄ‡∏û‡∏µ‡∏¢‡∏á', '‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î']
    neg_words = ['‡πÑ‡∏°‡πà‡∏î‡∏µ', '‡∏õ‡∏±‡∏ç‡∏´‡∏≤', '‡πÅ‡∏¢‡πà', '‡∏¢‡∏≤‡∏Å‡∏•‡∏≥‡∏ö‡∏≤‡∏Å', '‡∏Ç‡∏≤‡∏î‡πÅ‡∏Ñ‡∏•‡∏ô', '‡∏≠‡∏∏‡∏õ‡∏™‡∏£‡∏£‡∏Ñ', '‡∏´‡∏ô‡∏µ‡πâ‡∏™‡∏¥‡∏ô', '‡πÄ‡∏î‡∏∑‡∏≠‡∏î‡∏£‡πâ‡∏≠‡∏ô', '‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏≤‡∏¢']
    pos_score = sum(1 for w in pos_words if w in text)
    neg_score = sum(1 for w in neg_words if w in text)
    if pos_score > neg_score: return "‡∏Ñ‡πà‡∏≠‡∏ô‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏ö‡∏ß‡∏Å üòä"
    elif neg_score > pos_score: return "‡∏Ñ‡πà‡∏≠‡∏ô‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏•‡∏ö üòü"
    else: return "‡∏õ‡∏Å‡∏ï‡∏¥ / ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á üòê"

# --- 3. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå MS Word ---
def create_word_report(filename, sentiment, summary, keywords_df):
    doc = Document()
    doc.add_heading(f'‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: {filename}', 0)
    
    doc.add_heading('‡∏ú‡∏•‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå', level=1)
    doc.add_paragraph(sentiment)
    
    doc.add_heading('‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç', level=1)
    for s in summary:
        doc.add_paragraph(s, style='List Bullet')
        
    doc.add_heading('‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (Top Keywords)', level=1)
    table = doc.add_table(rows=1, cols=2)
    hdr_cells = table.rows[0].cells
    hdr_cells[0].text = '‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç'
    hdr_cells[1].text = '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á'
    for index, row in keywords_df.iterrows():
        row_cells = table.add_row().cells
        row_cells[0].text = str(row['‡∏Ñ‡∏≥'])
        row_cells[1].text = str(row['‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á'])
        
    bio = BytesIO()
    doc.save(bio)
    return bio.getvalue()

# --- 4. ‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Library ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ---
try:
    from pythainlp.summarize import summarize
    from pythainlp.tokenize import word_tokenize
    from pythainlp.corpus import thai_stopwords
    THAI_READY = True
except ImportError:
    THAI_READY = False

st.set_page_config(layout="wide", page_title="Research Tool with Download")
st.title("üìÇ ‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢ (Export Edition)")

if not THAI_READY:
    st.error("‚ùå ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Library")
    st.stop()

setup_font()
uploaded_files = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ö‡∏ó‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå (.txt)", type=['txt'], accept_multiple_files=True)

if uploaded_files:
    for file in uploaded_files:
        text = file.read().decode("utf-8")
        tokens = word_tokenize(text, keep_whitespace=False)
        stop_words = list(thai_stopwords())
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏≥: ‡∏¢‡∏≤‡∏ß >= 5 ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå
        filtered_by_length = [t.strip() for t in tokens if t.strip() and t not in stop_words and len(t.strip()) >= 5 and not re.match(r'^[0-9\W]+$', t)]
        word_counts = Counter(filtered_by_length)
        filtered_final = [word for word in filtered_by_length if word_counts[word] >= 3]
        
        with st.expander(f"üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: {file.name}", expanded=True):
            col1, col2 = st.columns(2)
            
            s_label = analyze_sentiment_thai(text)
            try:
                brief = summarize(text, n=2)
            except:
                brief = ["‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ"]

            with col1:
                st.subheader("üîç ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
                st.write(f"**‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå:** {s_label}")
                
                # --- ‡∏™‡πà‡∏ß‡∏ô Word Cloud ‡πÅ‡∏•‡∏∞‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ ---
                if filtered_final:
                    wc = WordCloud(width=800, height=400, background_color="white", regexp=r"[\u0e00-\u0e7f]+", font_path=font_path).generate(" ".join(filtered_final))
                    fig, ax = plt.subplots()
                    ax.imshow(wc, interpolation='bilinear')
                    ax.axis("off")
                    st.pyplot(fig)
                    
                    # ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î PNG
                    buf = BytesIO()
                    fig.savefig(buf, format="png")
                    st.download_button(label="üíæ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Word Cloud (PNG)", data=buf.getvalue(), file_name=f"wordcloud_{file.name}.png", mime="image/png")
                
            with col2:
                st.subheader("üìà ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ñ‡∏≥")
                final_counts = Counter(filtered_final).most_common(12)
                df_counts = pd.DataFrame(final_counts, columns=['‡∏Ñ‡∏≥', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á'])
                st.table(df_counts)
                
                # --- ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô Word ---
                word_data = create_word_report(file.name, s_label, brief, df_counts)
                st.download_button(label="üìÑ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô (MS Word)", data=word_data, file_name=f"report_{file.name}.docx", mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")

else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå")
