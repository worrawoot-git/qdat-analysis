import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import re
import matplotlib as mpl
from wordcloud import WordCloud

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ---
font_path = "Kanit-Regular.ttf" 

def setup_font():
    try:
        mpl.font_manager.fontManager.addfont(font_path)
        prop = mpl.font_manager.FontProperties(fname=font_path)
        mpl.rc('font', family=prop.get_name())
        mpl.rcParams['axes.unicode_minus'] = False 
        return True
    except:
        return False

# --- 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÅ‡∏ö‡∏ö‡∏ú‡∏™‡∏°‡∏ú‡∏™‡∏≤‡∏ô ---
def analyze_sentiment_thai(text):
    try:
        from pythainlp.sentiment import sentiment
        res = sentiment(text)
        if res == "pos": return "‡∏ö‡∏ß‡∏Å (Positive) üòä"
        if res == "neg": return "‡∏•‡∏ö (Negative) üòü"
    except:
        pass

    pos_words = ['‡∏î‡∏µ', '‡πÄ‡∏´‡πá‡∏ô‡∏î‡πâ‡∏ß‡∏¢', '‡∏†‡∏π‡∏°‡∏¥‡πÉ‡∏à', '‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç', '‡∏û‡∏±‡∏í‡∏ô‡∏≤', '‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå', '‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô', '‡∏û‡∏≠‡πÄ‡∏û‡∏µ‡∏¢‡∏á', '‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î']
    neg_words = ['‡πÑ‡∏°‡πà‡∏î‡∏µ', '‡∏õ‡∏±‡∏ç‡∏´‡∏≤', '‡πÅ‡∏¢‡πà', '‡∏¢‡∏≤‡∏Å‡∏•‡∏≥‡∏ö‡∏≤‡∏Å', '‡∏Ç‡∏≤‡∏î‡πÅ‡∏Ñ‡∏•‡∏ô', '‡∏≠‡∏∏‡∏õ‡∏™‡∏£‡∏£‡∏Ñ', '‡∏´‡∏ô‡∏µ‡πâ‡∏™‡∏¥‡∏ô', '‡πÄ‡∏î‡∏∑‡∏≠‡∏î‡∏£‡πâ‡∏≠‡∏ô', '‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏≤‡∏¢']
    
    pos_score = sum(1 for w in pos_words if w in text)
    neg_score = sum(1 for w in neg_words if w in text)
    
    if pos_score > neg_score: return "‡∏Ñ‡πà‡∏≠‡∏ô‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏ö‡∏ß‡∏Å üòä"
    elif neg_score > pos_score: return "‡∏Ñ‡πà‡∏≠‡∏ô‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏•‡∏ö üòü"
    else: return "‡∏õ‡∏Å‡∏ï‡∏¥ / ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏≤‡∏á üòê"

# --- 3. ‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Library ---
try:
    from pythainlp.summarize import summarize
    from pythainlp.tokenize import word_tokenize
    from pythainlp.corpus import thai_stopwords
    THAI_READY = True
except ImportError:
    THAI_READY = False

st.set_page_config(layout="wide", page_title="Professional Thai Research Tool")
st.title("üìÇ ‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏ó‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢ (Custom Filter Edition)")

if not THAI_READY:
    st.error("‚ùå ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Library ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢")
    st.stop()

setup_font()

uploaded_files = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ö‡∏ó‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå (.txt)", type=['txt'], accept_multiple_files=True)

if uploaded_files:
    comparison_data = []
    
    for file in uploaded_files:
        text = file.read().decode("utf-8")
        
        # ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥
        tokens = word_tokenize(text, keep_whitespace=False)
        stop_words = list(thai_stopwords())
        extra_stop = ['‡πÄ‡∏ô‡∏≤‡∏∞', '‡∏ô‡∏∞', '‡∏Ñ‡∏£‡∏±‡∏ö', '‡∏Ñ‡πà‡∏∞', '‡∏≠‡∏∑‡∏°', '‡πÄ‡∏≠‡πà‡∏≠']
        stop_words.extend(extra_stop)
        
        # --- ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÉ‡∏´‡∏°‡πà: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà 5 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç/‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå ---
        filtered_by_length = [
            t.strip() for t in tokens 
            if t.strip() and t not in stop_words and len(t.strip()) >= 5 and not re.match(r'^[0-9\W]+$', t)
        ]
        
        # --- ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÉ‡∏´‡∏°‡πà: ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà 3 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ ---
        word_counts_full = Counter(filtered_by_length)
        filtered_final = [word for word in filtered_by_length if word_counts_full[word] >= 3]
        
        with st.expander(f"üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: {file.name}", expanded=True):
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.subheader("üîç ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
                st.write(f"**‡πÇ‡∏ó‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏£‡∏ß‡∏°:** {analyze_sentiment_thai(text)}")
                
                try:
                    brief = summarize(text, n=2)
                    st.write("**‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:**")
                    for b in brief: st.write(f"üìå {b}")
                except:
                    st.write("**‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:** ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ")

                st.write("**Word Cloud (‡∏¢‡∏≤‡∏ß >= 5 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£ ‡πÅ‡∏•‡∏∞ ‡∏ã‡πâ‡∏≥ >= 3 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á):**")
                if filtered_final:
                    try:
                        wc = WordCloud(
                            width=800, height=400, 
                            background_color="white", 
                            regexp=r"[\u0e00-\u0e7f]+",
                            font_path=font_path
                        ).generate(" ".join(filtered_final))
                        
                        fig_wc, ax_wc = plt.subplots()
                        ax_wc.imshow(wc, interpolation='bilinear')
                        ax_wc.axis("off")
                        st.pyplot(fig_wc)
                    except:
                        st.write("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á Word Cloud ‡πÑ‡∏î‡πâ")
                else:
                    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç (‡∏¢‡∏≤‡∏ß >= 5 ‡πÅ‡∏•‡∏∞ ‡∏ã‡πâ‡∏≥ >= 3)")

            with col2:
                st.subheader("üìà ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç")
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 12 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß
                final_counts = Counter(filtered_final).most_common(12)
                if final_counts:
                    df_counts = pd.DataFrame(final_counts, columns=['‡∏Ñ‡∏≥', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á'])
                    st.bar_chart(df_counts.set_index('‡∏Ñ‡∏≥'))
                    st.table(df_counts)
                else:
                    st.write("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç")

            comparison_data.append({"‡πÑ‡∏ü‡∏•‡πå": file.name, "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å": analyze_sentiment_thai(text)})

    st.divider()
    st.subheader("üìã ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Ñ‡∏™")
    st.dataframe(pd.DataFrame(comparison_data), use_container_width=True)
else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
