import streamlit as st
from pythainlp.summarize import summarize
from pythainlp.tokenize import word_tokenize
from pythainlp.corpus import thai_stopwords
from pythainlp.sentiment import sentiment
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import pandas as pd
from collections import Counter

st.set_page_config(layout="wide", page_title="Advanced Thai Research Tool")

st.title("üìÇ ‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏†‡∏≤‡∏Ñ‡∏™‡∏ô‡∏≤‡∏° (Advanced Version)")
st.write("‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå: Word Cloud | Sentiment | Multi-File Analysis")

# 1. Multiple File Support: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
uploaded_files = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ö‡∏ó‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå (.txt)", type=['txt'], accept_multiple_files=True)

if uploaded_files:
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏•‡∏¥‡∏™‡∏ï‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
    all_data = []

    for file in uploaded_files:
        text = file.read().decode("utf-8")
        tokens = word_tokenize(text, keep_whitespace=False)
        stopwords = list(thai_stopwords())
        filtered_words = [t for t in tokens if t not in stopwords and len(t) > 1]
        
        # 2. Sentiment Analysis: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (‡∏ö‡∏ß‡∏Å/‡∏•‡∏ö)
        # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏ä‡πá‡∏Å‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏£‡∏ß‡∏°
        sent_result = sentiment(text) 
        sent_label = "‡∏ö‡∏ß‡∏Å (Positive)" if sent_result == "pos" else "‡∏•‡∏ö (Negative)" if sent_result == "neg" else "‡∏õ‡∏Å‡∏ï‡∏¥ (Neutral)"
        
        all_data.append({
            "filename": file.name,
            "text": text,
            "keywords": Counter(filtered_words).most_common(10),
            "sentiment": sent_label
        })

    # ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
    for data in all_data:
        with st.expander(f"üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå: {data['filename']}"):
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.write("**‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°:**", data['sentiment'])
                st.write("**‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:**")
                try:
                    summ = summarize(data['text'], n=2)
                    for s in summ: st.write(f"- {s}")
                except: st.write("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ")

                # 3. Word Cloud: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏≥
                st.write("**Word Cloud:**")
                # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Font ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö (‡∏£‡∏∞‡∏ö‡∏ö Streamlit Cloud ‡∏°‡∏±‡∏Å‡∏°‡∏µ font ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÉ‡∏´‡πâ)
                wc = WordCloud(font_path=None, width=800, height=400, background_color="white", regexp=r"[\u0e00-\u0e7f]+").generate(" ".join(filtered_words))
                fig, ax = plt.subplots()
                ax.imshow(wc, interpolation='bilinear')
                ax.axis("off")
                st.pyplot(fig)

            with col2:
                st.write("**‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢:**")
                df = pd.DataFrame(data['keywords'], columns=['‡∏Ñ‡∏≥', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô'])
                st.bar_chart(df.set_index('‡∏Ñ‡∏≥'))

    # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Ñ‡∏™
    st.divider()
    st.subheader("üìë ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Ñ‡∏™ (Cross-Case Comparison)")
    compare_df = pd.DataFrame([{"‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå": d['filename'], "‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå": d['sentiment']} for d in all_data])
    st.table(compare_df)

else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ö‡∏ó‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà 1 ‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")
