import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import re

# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Library ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏ö‡∏ö‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
try:
    from pythainlp.summarize import summarize
    from pythainlp.tokenize import word_tokenize
    from pythainlp.corpus import thai_stopwords
    from pythainlp import sentiment
    THAI_READY = True
except ImportError:
    THAI_READY = False

from wordcloud import WordCloud

st.set_page_config(layout="wide", page_title="Thai Research Tool")

st.title("üìÇ ‡∏£‡∏∞‡∏ö‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏ó‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå (Stable Version)")
st.markdown("---")

if not THAI_READY:
    st.error("‚ùå ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Library ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏ä‡πá‡∏Å‡πÑ‡∏ü‡∏•‡πå requirements.txt")
    st.stop()

uploaded_files = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ö‡∏ó‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå (.txt)", type=['txt'], accept_multiple_files=True)

if uploaded_files:
    summary_list = []
    for file in uploaded_files:
        text = file.read().decode("utf-8")
        
        with st.expander(f"üìë ‡πÑ‡∏ü‡∏•‡πå: {file.name}", expanded=True):
            col1, col2 = st.columns(2)
            
            # ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Stopwords
            tokens = word_tokenize(text, keep_whitespace=False)
            stop_words = list(thai_stopwords())
            filtered = [t for t in tokens if t not in stop_words and len(t) > 1 and not re.match(r'[0-9]+', t)]
            
            with col1:
                # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÅ‡∏ö‡∏ö‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡πà‡∏°
                st.subheader("üí° ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°")
                try:
                    s_val = sentiment(text)
                    s_label = "‡∏ö‡∏ß‡∏Å üòä" if s_val == "pos" else "‡∏•‡∏ö üòü" if s_val == "neg" else "‡∏õ‡∏Å‡∏ï‡∏¥ üòê"
                except:
                    s_label = "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ"
                
                st.write(f"**‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å‡∏£‡∏ß‡∏°:** {s_label}")
                
                st.write("**‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:**")
                try:
                    brief = summarize(text, n=2)
                    for b in brief: st.write(f"üìå {b}")
                except: st.write("- ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ")

                st.write("**Word Cloud:**")
                try:
                    wc = WordCloud(width=800, height=400, background_color="white", regexp=r"[\u0e00-\u0e7f]+").generate(" ".join(filtered))
                    fig, ax = plt.subplots()
                    ax.imshow(wc)
                    ax.axis("off")
                    st.pyplot(fig)
                except: st.write("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á Word Cloud ‡πÑ‡∏î‡πâ")

            with col2:
                st.subheader("üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ñ‡∏≥")
                counts = Counter(filtered).most_common(12)
                df = pd.DataFrame(counts, columns=['‡∏Ñ‡∏≥', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô'])
                st.bar_chart(df.set_index('‡∏Ñ‡∏≥'))
                st.table(df)

            summary_list.append({"‡πÑ‡∏ü‡∏•‡πå": file.name, "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏™‡∏∂‡∏Å": s_label})

    st.divider()
    st.subheader("üìã ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏Ñ‡∏™")
    st.dataframe(pd.DataFrame(summary_list), use_container_width=True)
else:
    st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏ñ‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô")
